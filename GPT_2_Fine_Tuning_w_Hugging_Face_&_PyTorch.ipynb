{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lpanigrahi/LORA-PEFT/blob/main/GPT_2_Fine_Tuning_w_Hugging_Face_%26_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# GPT-2 Fine-Tuning Tutorial with PyTorch & Huggingface in Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKGBoVwuhM4H"
      },
      "source": [
        "This is a simplified script for fine-tuning GPT2 using Hugging Face's [Transformers library](https://huggingface.co/transformers/) and PyTorch.\n",
        "\n",
        "You should understand the basics of PyTorch and how a training loop works before getting started. [This official PyTorch tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html) serves as an excellent introduction. Familiarity with the workings of GPT2 might be useful but isn't required. The code has been written for clarity and not re-use. I'd advise refactoring it for actual projects. I've liberally taken bits from [Chris McCormick's BERT fine-tuning tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/), [Ian Porter's GPT2 tutorial](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html) and the [Hugging Face Language model fine-tuning script](https://huggingface.co/transformers/v2.0.0/examples.html#language-model-fine-tuning) so full credit to them. Chris' code has pretty much provided the basis for this script - you should definitely check out his [blog](https://mccormickml.com/tutorials/).\n",
        "\n",
        "I should mention what the script doesn't cover:\n",
        "\n",
        "- Using the [nlp](https://huggingface.co/nlp/) library to load in the dataset and setting up the training workflow, which looks to streamline things rather nicely.\n",
        "- [Accumulated gradients](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255) - this gives larger effective batch sizes than Colab allows (GPT2 is a large model, and anything more than a batch size of 2 would be enough to get a CUDA out of memory error on Colab).\n",
        "- [Freezing layers](https://github.com/huggingface/transformers/issues/1431). This is the process of only changing the parameters in selected layers, made famous by the [ULMFit](https://arxiv.org/abs/1801.06146) process.\n",
        "- [Using 'past'](https://huggingface.co/transformers/quickstart.html#using-the-past) when generating text. This takes in the previous state when generating successive items of text. I didn't need it.\n",
        "- [Tensor packing](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html). This is a neat way of fitting in as much training data in each batch.\n",
        "- [Hyperparameter search](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10). I settled quickly on values that seemed to produce decent values, without checking if they were optimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43ed337-2463-4ca1-decd-fd94e9d623fa"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -U\n",
        "!pip install peft -U"
      ],
      "metadata": {
        "id": "S96pYFWqNnVu",
        "outputId": "dec94f9f-095f-4b24-c36d-fecf817337a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.33.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->peft) (0.17.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate->peft) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCCeyhuDHdOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6acd9f2-1d4f-4aa1-d23d-04641fdb5524"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# % matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, GPT2Model\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satxtOn9CzgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2483e69f-fc02-4a84-8bce-4a8036a4210b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep 23 05:02:54 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n",
        "\n",
        "The data used to finetune the language model is a set of around 1000 DJ biographies, with the aim of generating them in the same general format and style.\n",
        "\n",
        "This data isn't public so if you want to use this script, you'll have to source your own training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ1oK0kXaV5p"
      },
      "source": [
        "We need to get an idea of how long our training documents are.\n",
        "\n",
        "I'm not going to use the same tokenizer as the GPT2 one, which is a [byte pair encoding tokenizer](https://blog.floydhub.com/tokenization-nlp/). Instead, I'm using a simple one just to get a rough understanding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UQcu5s11MVif",
        "outputId": "229fa89a-4c7d-4cbb-ab37-3956345112e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_DIR = '/content/drive/MyDrive/workbook/GPT2-PEFT'"
      ],
      "metadata": {
        "id": "SFf1p7lVMc6m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {WORKING_DIR}"
      ],
      "metadata": {
        "id": "ZAP-MLgMMgSX",
        "outputId": "9335c16d-098a-4150-91e2-c3cd1b0726c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/workbook/GPT2-PEFT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"iamtarun/python_code_instructions_18k_alpaca\"\n",
        "dataset_split = \"train\"\n",
        "# Load dataset from the hub\n",
        "dataset = load_dataset(dataset_name, split=dataset_split)\n",
        "# Show dataset size\n",
        "print(f\"dataset size: {len(dataset)}\")"
      ],
      "metadata": {
        "id": "qMMhUN6wMkNN",
        "outputId": "8b49596a-8e0d-49e1-83c4-ffe2f0ef733e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size: 18612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "2Z2fnmDXOPrD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize the instruction dataset"
      ],
      "metadata": {
        "id": "hb3QRHBDOZMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['prompt'], padding=\"max_length\", truncation=True)"
      ],
      "metadata": {
        "id": "3UImsotBOgLp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "UAMfg4CDPB0O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "h2Td0C10Ol_I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "OXLkdUCaUSMO",
        "outputId": "7bee2679-6890-4df7-d66e-57766dfb79de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 18612\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dataset = tokenized_dataset.remove_columns(['instruction', 'input', 'output', 'prompt'])"
      ],
      "metadata": {
        "id": "WGaBALyhS0G-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset['prompt'][1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "UpRj3ER3A-kn",
        "outputId": "2ec1ac75-5d48-4fb9-f59b-20957d1acd20"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDesign a function in Python to find the maximum pair sum from the list input.\\n\\n### Input:\\ninput_list = [20, 11, 33, 67, 89 ,34]\\n\\n### Output:\\ndef maxPairSum(input_list):\\n\\n    #assume the first and second elements are the max pair\\n    max_pair_sum = input_list[0] + input_list[1]\\n\\n    # Keep track of the max pair\\n    pair_index_one = 0\\n    pair_index_two = 1\\n\\n    # iterate through the entire list\\n    for index_one in range(0, len(input_list)):\\n        for index_two in range(index_one + 1, len(input_list)):\\n\\n            # if the current pair sum is greater than the max pair sum\\n            # update the max pair sum and the pair indices\\n            if input_list[index_one] + input_list[index_two] > max_pair_sum:\\n                max_pair_sum = input_list[index_one] + input_list[index_two]\\n                pair_index_one = index_one\\n                pair_index_two = index_two\\n\\n    #return the max pair sum\\n    return max_pair_sum'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenized_dataset['input_ids'][1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "z3bF8f3SBXVy",
        "outputId": "3e1d2519-add1-4e42-a630-5da55640fa6c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDesign a function in Python to find the maximum pair sum from the list input.\\n\\n### Input:\\ninput_list = [20, 11, 33, 67, 89,34]\\n\\n### Output:\\ndef maxPairSum(input_list):\\n\\n    #assume the first and second elements are the max pair\\n    max_pair_sum = input_list[0] + input_list[1]\\n\\n    # Keep track of the max pair\\n    pair_index_one = 0\\n    pair_index_two = 1\\n\\n    # iterate through the entire list\\n    for index_one in range(0, len(input_list)):\\n        for index_two in range(index_one + 1, len(input_list)):\\n\\n            # if the current pair sum is greater than the max pair sum\\n            # update the max pair sum and the pair indices\\n            if input_list[index_one] + input_list[index_two] > max_pair_sum:\\n                max_pair_sum = input_list[index_one] + input_list[index_two]\\n                pair_index_one = index_one\\n                pair_index_two = index_two\\n\\n    #return the max pair sum\\n    return max_pair_sum<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sample_dataset)"
      ],
      "metadata": {
        "id": "YS-WFUSTfWcQ",
        "outputId": "026fbd98-fb52-4c59-ace6-9ab5119752b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18612"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6x6pk_3xsjuy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, gpt2_type=\"gpt2\"):\n",
        "\n",
        "    self.input_ids = [torch.tensor(x) for x in txt_list['input_ids']]\n",
        "    self.attn_masks = [torch.tensor(x) for x in txt_list['attention_mask']]\n",
        "\n",
        "    # for i in range(len(txt_list)):\n",
        "\n",
        "    #   self.input_ids.append(torch.tensor(txt_list['input_ids'][0]))\n",
        "    #   self.attn_masks.append(torch.tensor(txt_list['attention_mask'][0]))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx]"
      ],
      "metadata": {
        "id": "95PsKerkXZ2M"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = sample_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)"
      ],
      "metadata": {
        "id": "MEtplOwG0vb8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset"
      ],
      "metadata": {
        "id": "VHnm-12m1aeB",
        "outputId": "0bc39f27-f547-4cbb-db14-bad175ce135e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 16750\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 1862\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = GPT2Dataset(split_dataset['train'])"
      ],
      "metadata": {
        "id": "yfCrrqEQ1GJO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = GPT2Dataset(split_dataset['test'])"
      ],
      "metadata": {
        "id": "aExoG-KG1WKS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4"
      ],
      "metadata": {
        "id": "DhLDATIK19Mp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            test_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "JYpHESl111Tl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "ELXfW-_PsB0p",
        "outputId": "5f422e69-cf3d-4dcd-f451-800d4588a2f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[21106,   318,   281,  ..., 50256, 50256, 50256],\n",
              "         [21106,   318,   281,  ..., 50256, 50256, 50256],\n",
              "         [21106,   318,   281,  ..., 50256, 50256, 50256],\n",
              "         [21106,   318,   281,  ..., 50256, 50256, 50256]]),\n",
              " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]])]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "GPT2 is a large model. Increasing the batch size above 2 has lead to out of memory problems. This can be mitigated by accumulating the gradients but that is out of scope here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2-large', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "original_model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "# model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "# # Tell pytorch to run this model on the GPU.\n",
        "# device = torch.device(\"cpu\")\n",
        "# model.cpu()\n",
        "\n",
        "# # Set the seed value all over the place to make this reproducible.\n",
        "# seed_val = 42\n",
        "\n",
        "# random.seed(seed_val)\n",
        "# np.random.seed(seed_val)\n",
        "# torch.manual_seed(seed_val)\n",
        "# torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Post-processing on the model"
      ],
      "metadata": {
        "id": "356Z4AlgEpW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = original_model\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False  # freeze the model - train adapters later\n",
        "  if param.ndim == 1:\n",
        "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
        "    param.data = param.data.to(torch.float32)\n",
        "\n",
        "model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "class CastOutputToFloat(nn.Sequential):\n",
        "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
        "model.lm_head = CastOutputToFloat(model.lm_head)"
      ],
      "metadata": {
        "id": "ounvmAgVEmqs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBEVY2PYSTXJ"
      },
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 1\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 500"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42fc947-3804-4864-870f-c5f21dd91b52"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = warmup_steps,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup PEFT/LoRA Finetuning"
      ],
      "metadata": {
        "id": "Hxg63Js_lY_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
      ],
      "metadata": {
        "id": "Jti99AF-lca2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2-large', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "original_model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\", config=configuration)"
      ],
      "metadata": {
        "id": "4_a1Hhyf_lrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original_model = GPT2LMHeadModel.from_pretrained('gpt2-large', torch_dtype=torch.bfloat16)"
      ],
      "metadata": {
        "id": "W5dxfR7yroqS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = original_model\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False  # freeze the model - train adapters later\n",
        "  if param.ndim == 1:\n",
        "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
        "    param.data = param.data.to(torch.float32)\n",
        "\n",
        "model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "class CastOutputToFloat(nn.Sequential):\n",
        "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
        "model.lm_head = CastOutputToFloat(model.lm_head)"
      ],
      "metadata": {
        "id": "SgysTIUUHrUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "        r=32,\n",
        "        lora_alpha=32,\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        # tune the embedding layer and prediction head\n",
        "        modules_to_save=[\"wte\", \"lm_head\"]\n",
        "        # modules_to_save=[\"wte\"]\n",
        ")"
      ],
      "metadata": {
        "id": "iRmVAeQUl-Vn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model,\n",
        "                        lora_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjGuwd1vmFCO",
        "outputId": "16c8bd78-b74d-4a68-f9ab-50a63fc984c1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(print_number_of_trainable_model_parameters(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvy_qe0PmPdA",
        "outputId": "c0d3024d-3d2d-4fdd-b3d1-d586c39071f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable model parameters: 5898240\n",
            "all model parameters: 779928320\n",
            "percentage of trainable model parameters: 0.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 1\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 500"
      ],
      "metadata": {
        "id": "iRj_5Ecz5AdG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_qnXYYs5VaW",
        "outputId": "ad30fa60-58cd-4bdc-e4f3-65d95bbf0a24"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = warmup_steps,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "cZ5zOi865Wce"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "metadata": {
        "id": "iS4quda7V1At"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPohrZ-CTWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "73edc3f0-d246-4832-b3be-cd191c14e918"
      },
      "source": [
        "device='cuda'\n",
        "# model = peft_model\n",
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        # batch.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(  input_ids = b_input_ids,\n",
        "                          labels=b_labels,\n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "        # outputs = model(**batch)\n",
        "\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,\n",
        "                                    top_k=50,\n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95,\n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "\n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            outputs  = model(b_input_ids,\n",
        "#                            token_type_ids=None,\n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-653aebf5d80c>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "74712011-9ff4-4da5-9e0e-5ff1546ad310"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "# pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1           0.258107     0.199251       1:40:23         0:03:33"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7288efea-3959-439e-bd57-24b7299e8a6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.258107</td>\n",
              "      <td>0.199251</td>\n",
              "      <td>1:40:23</td>\n",
              "      <td>0:03:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7288efea-3959-439e-bd57-24b7299e8a6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7288efea-3959-439e-bd57-24b7299e8a6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7288efea-3959-439e-bd57-24b7299e8a6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "2af567df-1aab-4f44-e8ef-9b65b86e1fbd"
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# Display Model Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b33002-0ca7-420a-d196-ce77bcdbe558"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50257, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "# Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a5d5f0-dac4-41fb-c2dc-8f4371776ca7"
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.json',\n",
              " './model_save/merges.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a960823-79bd-4318-a9ea-7cd428fe20c0"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 487565K\n",
            "-rw------- 1 root root      1K Sep 21 19:51 config.json\n",
            "-rw------- 1 root root      1K Sep 21 19:51 generation_config.json\n",
            "-rw------- 1 root root    446K Sep 21 19:51 merges.txt\n",
            "-rw------- 1 root root 486140K Sep 21 19:51 pytorch_model.bin\n",
            "-rw------- 1 root root      1K Sep 21 19:51 special_tokens_map.json\n",
            "-rw------- 1 root root      1K Sep 21 19:51 tokenizer_config.json\n",
            "-rw------- 1 root root    976K Sep 21 19:51 vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "750913ea-1548-476a-9c73-a3ec61385a53"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 475M Sep 21 19:51 ./model_save/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0186aa25-95fe-4c03-d4a5-fe4b16dd66e5"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "# !cp -r ./model_save/ $data_dir\n",
        "output_dir = './model_save'\n",
        "device = 'cpu'\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Write a program to convert farenhite to celcious'\n",
        "input = ''\n",
        "prompt = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\\n",
        "\n",
        "### Instruction:\\\n",
        "{text}\\\n",
        "\n",
        "### Input:\\\n",
        "{input}\\\n",
        "### Output:\"\"\""
      ],
      "metadata": {
        "id": "LtMTN4dzFuhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Write a program to calculate farenhite to celcious'\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHriNh_XC3y6",
        "outputId": "ca05518f-fec2-4078-be23-4080d980fb76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "### Instruction:Write a program to calculate farenhite to celcious\n",
            "### Input:### Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4XhewaV93-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "829dc790-8881-43dc-e301-ffa7d4b7e56b"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "# prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "# ### Instruction:\n",
        "# {text}\n",
        "# ### Input:\n",
        "# {}\n",
        "# ### Output:\"\"\"\n",
        "\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated,\n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,\n",
        "                                top_k=50,\n",
        "                                max_length = 1000,\n",
        "                                top_p=0.95,\n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
            "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198, 21017,\n",
            "         46486,    25, 16594,   257,  1430,   284, 10385,   277,  5757,    71,\n",
            "           578,   284, 18725,  4680,   198, 21017, 23412,    25, 21017, 25235,\n",
            "            25]])\n",
            "0: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "### Instruction:Write a program to convert farenhite to celcious\n",
            "### Input:### Output:\n",
            "def farenhite_to_celcious(f, lhs):\n",
            "  celsius = 0\n",
            "  longitude = 0\n",
            "  while (lhs!= 0 and lhs!= 0):\n",
            "    temp = temp + lhs\n",
            "    s = lhs - lhs\n",
            "\n",
            "    if (lhs > s):\n",
            "       celery_celcious = lhs\n",
            "\n",
            "    else:\n",
            "        celery_celcious = f\n",
            "\n",
            "        longitude += celery_celcious + longitude\n",
            "    else:\n",
            "        celery_celcious = lhs - lhs\n",
            "\n",
            "    return celery_celcious, celery_celcious\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4LrX5H-0nAU"
      },
      "source": [
        "These aren't bad at all!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gh6HlYLGDGID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7LCCdET7DHKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v_dZtdeGDHjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C1xY4-HXDHyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wnzt84QsDIBi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}